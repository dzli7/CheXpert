# -*- coding: utf-8 -*-
"""faster_diaphragm_removal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GXzaWnrBNLDLCTx_7jPqP1MaKv2aUeoW
"""

import numpy as np
import cv2
from PIL import Image
import torch
import torchvision.transforms as T
from torch.utils.data import DataLoader
import torch.utils.data as data_utils
import time
import math
import pandas as pd

def timeSince(since):
    now = time.time()
    s = now - since
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)


label_columns = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly','Lung Opacity', 
    'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia','Atelectasis', 'Pneumothorax', 'Pleural Effusion', 
    'Pleural Other','Fracture', 'Support Devices']

# create 14 separate dfs, one for each disease

data_path = '/central/groups/CS156b/data/'
train_path = data_path + 'student_labels/train.csv'
test_path = data_path + 'student_labels/test_ids.csv'
imagesize = (128, 128)
resize = T.Resize(size=imagesize)
totensor = T.ToTensor()
process = T.Compose([resize, totensor])

def trainload(X, Y):
    trainx = torch.from_numpy(np.array(X).astype(np.float32))
    trainy = torch.from_numpy(np.array(Y).astype(np.float32))

    traindata = data_utils.TensorDataset(trainx, trainy)
    train_loader = DataLoader(traindata, batch_size=256, shuffle=True, pin_memory=True)
    return train_loader

def get_train_data():
    df = pd.read_csv(train_path).fillna(0)
    X = []
    Y = []
    
    i = 0
    df_dict = df.to_dict('records')
    for row in df_dict:
        if i >= int(df.shape[0]*0.01) - 1:
            break
        image_path = data_path + row['Path']
        
        image_nodi = remove_diaphragm(image_path)
        X.append(process(image_nodi).numpy())
        
        labels = []
        for label in label_columns:
            labels.append(row[label])

        Y.append(labels)

        i += 1

    return trainload(X,Y)

def remove_diaphragm(path):
  img = cv2.imread(path, 1)
  img_copy = np.copy(img)
  img_copy_master = np.copy(img)

  max_pixel = 0
  min_pixel = 300

  ret, img = cv2.threshold(img, 229.5, 255, cv2.THRESH_BINARY)

  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  components = cv2.connectedComponentsWithStats(gray)
  (numLabels, labels, stats, centroids) = components

  # Find max area and start at 1 because 0 is background
  areas = []
  for i in range(1, numLabels):
    areas.append(stats[i, cv2.CC_STAT_AREA])

  mask = np.zeros(gray.shape, dtype="uint8")

  # Keep largest area and remove others
  max_area = max(areas)
  for i in range(numLabels):
    area = stats[i, cv2.CC_STAT_AREA]
    if area == max_area:
      componentMask = (labels == i).astype("uint8") * 255
      mask = cv2.bitwise_or(mask, componentMask)
    
  #cv2_imshow(mask)

  # Fill holes with closing
  kernel = np.ones((20,20),np.uint8)
  closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
  #cv2_imshow(closing)

  # Smooth boundary
  kernel = np.ones((20,20),np.uint8)
  opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)

  # ret, opening = cv2.threshold(opening, 229.5, 255, cv2.THRESH_BINARY_INV)
  #cv2.imwrite(path[0:(len(path)-4)] + 'mask.jpg', opening)
  # cv2_imshow(opening)

  img1 = Image.open(path)
  
  # Opening the secondary image (overlay image)
  #img2 = Image.open(path[0:(len(path)-4)] + 'mask.jpg')    
  img2 = Image.fromarray(opening)
    
  # Pasting img2 image on top of img1 
  # starting at coordinates (0, 0)
  img1.paste(img2, (0,0), mask = img2)

  na = np.array(img1.convert('L'))

  # Get x,y coordinates of black pixels
  Y, X = np.where(na==255)

  # Make pixels 30 across and 30 down from them black
  na[Y, X] = 0

  # Convert back to PIL Image and save
  img1 = Image.fromarray(na)
  return img1

def main():
    start = time.time()
    _ = get_train_data()
    print(timeSince(start))

if __name__ == '__main__':
    main()

